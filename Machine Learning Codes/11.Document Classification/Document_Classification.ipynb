{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "LSTM_Assignment_Submission_Parth.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frm3EHioy8cM",
        "colab_type": "text"
      },
      "source": [
        "## Assignment : 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N5Ke63dy8c0",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Preprocess all the Data we have in DonorsChoose <a href='https://drive.google.com/drive/folders/1MIwK7BQMev8f5CbDDVNLPaFGB32pFN60'>Dataset</a> use train.csv\n",
        "2. Combine 4 essay's into one column named - 'preprocessed_essays'. \n",
        "3. After step 2 you have to train 3 types of models as discussed below. \n",
        "4. For all the model use <a href='https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics'>'auc'</a> as a metric. check <a href='https://datascience.stackexchange.com/a/20192'>this</a> for using auc as a metric \n",
        "5. You are free to choose any number of layers/hiddden units but you have to use same type of architectures shown below. \n",
        "6. You can use any one of the optimizers and choice of Learning rate and momentum, resources: <a href='http://cs231n.github.io/neural-networks-3/'>cs231n class notes</a>, <a href='https://www.youtube.com/watch?v=hd_KFJ5ktUc'>cs231n class video</a>. \n",
        "7. For all the model's use <a href='https://www.youtube.com/watch?v=2U6Jl7oqRkM'>TensorBoard</a> and plot the Metric value and Loss with epoch. While submitting, take a screenshot of plots and include those images in .ipynb notebook and PDF. \n",
        "8. Use Categorical Cross Entropy as Loss to minimize.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebytx50i3d0s",
        "colab_type": "code",
        "outputId": "f036eedb-5f3e-4615-a320-10b6c11993f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "! wget --header=\"Host: doc-14-24-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://drive.google.com/drive/u/0/folders/1CJnItndeSSJu7aragQoXWZS9-0apN6pp\" --header=\"Cookie: AUTH_t5qon8tobs4crgo9e5mfjphsf8l1st7h_nonce=k62nn9pam11l2\" --header=\"Connection: keep-alive\" \"https://doc-14-24-docs.googleusercontent.com/docs/securesc/nji0agiogjqo3r2b8t0lib5qttb9sgab/bb8klbdb7ta4qcrmdqcgnfeanus3elmm/1591417800000/00484516897554883881/00113621618736444193/1GpATd_pM4mcnWWIs28-s1lgqdAg2Wdv-?e=download&authuser=0&nonce=k62nn9pam11l2&user=00113621618736444193&hash=8d83r4fvns98s8blmtrh1pk3nr6fr8aa\" -c -O 'preprocessed_data.csv'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-06 04:31:50--  https://doc-14-24-docs.googleusercontent.com/docs/securesc/nji0agiogjqo3r2b8t0lib5qttb9sgab/bb8klbdb7ta4qcrmdqcgnfeanus3elmm/1591417800000/00484516897554883881/00113621618736444193/1GpATd_pM4mcnWWIs28-s1lgqdAg2Wdv-?e=download&authuser=0&nonce=k62nn9pam11l2&user=00113621618736444193&hash=8d83r4fvns98s8blmtrh1pk3nr6fr8aa\n",
            "Resolving doc-14-24-docs.googleusercontent.com (doc-14-24-docs.googleusercontent.com)... 74.125.23.132, 2404:6800:4008:c02::84\n",
            "Connecting to doc-14-24-docs.googleusercontent.com (doc-14-24-docs.googleusercontent.com)|74.125.23.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘preprocessed_data.csv’\n",
            "\n",
            "\rpreprocessed_data.c     [<=>                 ]       0  --.-KB/s               \rpreprocessed_data.c     [ <=>                ]  32.01M  95.9MB/s               \rpreprocessed_data.c     [  <=>               ]  88.01M   134MB/s               \rpreprocessed_data.c     [   <=>              ] 118.69M   139MB/s    in 0.9s    \n",
            "\n",
            "2020-06-06 04:31:51 (139 MB/s) - ‘preprocessed_data.csv’ saved [124454659]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEmoG0qIlz4a",
        "colab_type": "code",
        "outputId": "a740e0a8-16c4-4f39-8d5d-8dac8f68569c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "! wget --header=\"Host: doc-0o-1g-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://drive.google.com/drive/folders/1MIwK7BQMev8f5CbDDVNLPaFGB32pFN60\" --header=\"Cookie: AUTH_t5qon8tobs4crgo9e5mfjphsf8l1st7h=00113621618736444193|1590297750000|ockvtqj5njrftgm5tno869g09oiu81o4\" --header=\"Connection: keep-alive\" \"https://doc-0o-1g-docs.googleusercontent.com/docs/securesc/nji0agiogjqo3r2b8t0lib5qttb9sgab/v9163u1hhn9v6mbq5cqospqiqre5ala8/1590297825000/06629147635963609455/00113621618736444193/1tY2a4l7YGAjCh-gZ7pN_oilTtCLHfa4E?e=download&authuser=0\" -c -O 'glove.42B.300d.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 05:25:04--  https://doc-0o-1g-docs.googleusercontent.com/docs/securesc/nji0agiogjqo3r2b8t0lib5qttb9sgab/v9163u1hhn9v6mbq5cqospqiqre5ala8/1590297825000/06629147635963609455/00113621618736444193/1tY2a4l7YGAjCh-gZ7pN_oilTtCLHfa4E?e=download&authuser=0\n",
            "Resolving doc-0o-1g-docs.googleusercontent.com (doc-0o-1g-docs.googleusercontent.com)... 74.125.28.132, 2607:f8b0:400e:c04::84\n",
            "Connecting to doc-0o-1g-docs.googleusercontent.com (doc-0o-1g-docs.googleusercontent.com)|74.125.28.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip      [   <=>              ]   1.75G  93.2MB/s    in 18s     \n",
            "\n",
            "2020-05-24 05:25:22 (99.1 MB/s) - ‘glove.42B.300d.zip’ saved [1877802108]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRwXXhAOMwuc",
        "colab_type": "code",
        "outputId": "c928c85c-daab-4634-e7c4-f555c3fc800e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "! wget --header=\"Host: downloads.cs.stanford.edu\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: _ga=GA1.2.184352224.1588061371; _gid=GA1.2.828696271.1590298829; _gat=1\" --header=\"Connection: keep-alive\" \"http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\" -c -O 'glove.6B.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 05:42:28--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.09MB/s    in 6m 27s  \n",
            "\n",
            "2020-05-24 05:48:55 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZo-jmNii4J",
        "colab_type": "code",
        "outputId": "42f9a3d6-e926-4c9b-e463-fbce61e323b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "! pip install pyunpack"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/33/fd/4b64817a1d82df78553ceb1bfc5a2d7ac162da8667be586430fab9db5deb/pyunpack-0.2.1-py2.py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/46/0a/6156f1bc14a44094cff75bb6ecefe1f8e8a12cfff66379ba3d52d0916c49/entrypoint2-0.2.1-py2.py3-none-any.whl\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Installing collected packages: easyprocess, argparse, entrypoint2, pyunpack\n",
            "Successfully installed argparse-1.4.0 easyprocess-0.3 entrypoint2-0.2.1 pyunpack-0.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TRYiTpy83Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('preprocessed_data.csv')\n",
        "X = data.drop('project_is_approved',axis = 1)\n",
        "Y = data['project_is_approved']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1dxccIR6zsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyunpack import Archive\n",
        "Archive('glove.6B.zip').extractall('folder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxR5Z573qLQq",
        "colab_type": "code",
        "outputId": "8b62e46a-61b9-4803-fdaf-2c7f1dac973c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "X.head(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school_state</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "      <th>essay</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ca</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_prek_2</td>\n",
              "      <td>53</td>\n",
              "      <td>math_science</td>\n",
              "      <td>appliedsciences health_lifescience</td>\n",
              "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
              "      <td>725.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school_state  ...   price\n",
              "0           ca  ...  725.05\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhSluDKuy8dH",
        "colab_type": "text"
      },
      "source": [
        "### Model-1\n",
        "\n",
        "Build and Train deep neural network as shown below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4maIu-QTy8dQ",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://i.imgur.com/w395Yk9.png'>\n",
        "ref: https://i.imgur.com/w395Yk9.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdEs0Efmy8de",
        "colab_type": "text"
      },
      "source": [
        "- __Input_seq_total_text_data__ --- You have to give Total text data columns. After this use the Embedding layer to get word vectors. Use given predefined glove word vectors, don't train any word vectors. After this use LSTM and get the LSTM output and Flatten that output. \n",
        "- __Input_school_state__ --- Give 'school_state' column as input to embedding layer and Train the Keras Embedding layer. \n",
        "- __Project_grade_category__  --- Give 'project_grade_category' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_clean_categories__ --- Give 'input_clean_categories' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_clean_subcategories__ --- Give 'input_clean_subcategories' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_clean_subcategories__ --- Give 'input_teacher_prefix' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_remaining_teacher_number_of_previously_posted_projects._resource_summary_contains_numerical_digits._price._quantity__ ---concatenate remaining columns and add a Dense layer after that. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGKg-QHDy8d8",
        "colab_type": "text"
      },
      "source": [
        "- For LSTM, you can choose your sequence padding methods on your own or you can train your LSTM without padding, there is no restriction on that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32_6M0Oey8eM",
        "colab_type": "text"
      },
      "source": [
        "Below is an example of embedding layer for a categorical columns. In below code all are dummy values, we gave only for referance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odcbDtUG-rxm",
        "colab_type": "text"
      },
      "source": [
        "Import files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5bnLgSM7QVr",
        "colab_type": "code",
        "outputId": "a2ca9d9b-9fec-4fc0-be26-80e2b774c664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras import backend as K"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AT6V15qbG0u",
        "colab_type": "code",
        "outputId": "ad5f9695-6aef-44ee-b439-d4478c8f8929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "lengths = []\n",
        "for i in data['essay']:\n",
        "  l = i.split(' ')\n",
        "  lengths.append(len(l))\n",
        "plt.hist(lengths)\n",
        "max(lengths)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "339"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO0l8BN4-uzT",
        "colab_type": "text"
      },
      "source": [
        "Generate Model structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFX2WDui-yu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42,stratify=Y)\n",
        "# convert to one hot encoing \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(np.array(y_train).reshape(-1, 1))\n",
        "y_train = enc.transform(np.array(y_train).reshape(-1, 1))\n",
        "y_test = enc.transform(np.array(y_test).reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbQNXE0LcLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUxVVAvjBKHO",
        "colab_type": "text"
      },
      "source": [
        "#Encoding features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0eD0FwKGSOK",
        "colab_type": "text"
      },
      "source": [
        "essay text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vQ6vpjn38uT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wwGbloEBv8X",
        "colab_type": "code",
        "outputId": "3a77dc8e-297f-47cf-eb08-31ae5ffd5daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "X_train['essay'] =  X_train['essay'].str.replace('\\d+', '')\n",
        "X_test['essay'] =  X_test['essay'].str.replace('\\d+', '')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrYlrQJXH-yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_train['essay'])\n",
        "\n",
        "X_train_essay = t.texts_to_sequences(X_train['essay'])\n",
        "X_test_essay = t.texts_to_sequences(X_test['essay'])\n",
        "\n",
        "X_train_essay = pad_sequences(X_train_essay, maxlen=340, padding='post')\n",
        "X_test_essay = pad_sequences(X_test_essay,  maxlen=340, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPDXaAkJ-nA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('folder/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = values[1:]\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omnYCmCeM16D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(t.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "del embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ltWb1lnBJwf",
        "colab_type": "text"
      },
      "source": [
        "school_state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGsN4n52_ATx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(X_train['school_state'])\n",
        "X_train_school_state = le.transform(X_train['school_state'])\n",
        "X_test_school_state = le.transform(X_test['school_state'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRIzVA1mBqWZ",
        "colab_type": "text"
      },
      "source": [
        "project_grade_category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4EUBmd8Btqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(X_train['project_grade_category'])\n",
        "X_train_project_grade_category = le.transform(X_train['project_grade_category'])\n",
        "X_test_project_grade_category = le.transform(X_test['project_grade_category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-kJW8pZB7Cj",
        "colab_type": "text"
      },
      "source": [
        "clean_categories\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrbLjCZgB7hQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(X_train['clean_categories'])\n",
        "X_train_clean_categories = le.transform(X_train['clean_categories'])\n",
        "X_test_clean_categories = le.transform(X_test['clean_categories'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPUPFZr_B8jq",
        "colab_type": "text"
      },
      "source": [
        "clean_subcategories\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUkrWJquB9J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "s = list(set(X['clean_subcategories']))\n",
        "count = 0\n",
        "dic = {}\n",
        "for i in s:\n",
        "  dic[i] = count\n",
        "  count = count + 1\n",
        "X_train_clean_subcategories = X_train['clean_subcategories'].map(dic)\n",
        "X_test_clean_subcategories  = X_test['clean_subcategories'].map(dic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wmy_NEYBQkj",
        "colab_type": "text"
      },
      "source": [
        "tacher_prefix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_VvYXD7BRup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(X_train['teacher_prefix'])\n",
        "X_train_teacher_prefix = le.transform(X_train['teacher_prefix'])\n",
        "X_test_teacher_prefix = le.transform(X_test['teacher_prefix'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia30XkXUTIF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_previousproject_price = X_train[['teacher_number_of_previously_posted_projects','price']]\n",
        "X_test_previousproject_price = X_test[['teacher_number_of_previously_posted_projects','price']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izNavWA_Y4Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total_text\n",
        "input_layer1 = Input(shape=(340,))\n",
        "embedding1 = Embedding(48955, 300,weights=[embedding_matrix], input_length=340)(input_layer1)  #56381\n",
        "lstm = LSTM(64,return_sequences=True)(embedding1)\n",
        "flatten1 = Flatten()(lstm)\n",
        "\n",
        "#school_state\n",
        "input_layer2 = Input(shape=(1,))\n",
        "embedding2 = Embedding(51, 5, input_length=1)(input_layer2)\n",
        "flatten2 = Flatten()(embedding2)\n",
        "\n",
        "#project_grade_category\n",
        "input_layer3 = Input(shape=(1,))\n",
        "embedding3 = Embedding(4, 5, input_length=1)(input_layer3)\n",
        "flatten3 = Flatten()(embedding3)\n",
        "\n",
        "#clean_category\n",
        "input_layer4 = Input(shape=(1,))\n",
        "embedding4 = Embedding(51, 5, input_length=1)(input_layer4)\n",
        "flatten4 = Flatten()(embedding4)\n",
        "\n",
        "#clean_subcategories\n",
        "input_layer5 = Input(shape=(1,))\n",
        "embedding5 = Embedding(401, 20, input_length=1)(input_layer5)\n",
        "flatten5 = Flatten()(embedding5)\n",
        "\n",
        "#teacher_prefix\n",
        "input_layer6 = Input(shape=(1,))\n",
        "embedding6 = Embedding(5, 5, input_length=1)(input_layer6)\n",
        "flatten6 = Flatten()(embedding6)\n",
        "\n",
        "#price , teacher_number_of_previously_posted_projects\n",
        "input_layer7 = Input(shape=(2,))\n",
        "dense1 = Dense(2)(input_layer7)\n",
        "\n",
        "merged = Concatenate(axis = -1)([flatten1,flatten2,flatten3,flatten4,flatten5,flatten6,dense1])\n",
        "dense2 = Dense(128,activation = \"sigmoid\")(merged)\n",
        "\n",
        "dense3 = Dense(64,activation = \"sigmoid\")(dense2)\n",
        "\n",
        "dense4 = Dense(64,activation = \"sigmoid\")(dense3)\n",
        "\n",
        "dense5 = Dense(32,activation = \"sigmoid\")(dense4)\n",
        "\n",
        "dense6 = Dense(32,activation = \"sigmoid\")(dense5)\n",
        "\n",
        "dense7 = Dense(32,activation = \"sigmoid\")(dense6)\n",
        "\n",
        "output = Dense(2,activation = \"softmax\")(dense7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL4uKt3oedsi",
        "colab_type": "text"
      },
      "source": [
        "metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rStHHOJ3ecBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reference Link : https://stackoverflow.com/questions/37657260/how-to-implement-custom-metric-in-keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow import py_function\n",
        "   \n",
        "def auroc(y_true,y_pred):\n",
        "  try:\n",
        "    return tf.py_function(roc_auc_score , (y_true,y_pred) , tf.double)\n",
        "  except ValueError:\n",
        "      pass\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0IgJVPmPmVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.todense()\n",
        "y_test = y_test.todense()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwjV2lwOwBXz",
        "colab_type": "code",
        "outputId": "81f458b8-b5eb-4c67-e458-67195db15b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import datetime\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFk7--v8Uf8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_layer1,input_layer2,input_layer3,input_layer4,input_layer5,input_layer6,input_layer7],outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[auroc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkyNUghtGOOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "6b9678cf-a5e8-46e6-dfde-01e228f0a2ba"
      },
      "source": [
        "model.fit(\n",
        "    [X_train_essay,X_train_school_state,X_train_project_grade_category,X_train_clean_categories,X_train_clean_subcategories,X_train_teacher_prefix ,X_train_previousproject_price],y_train ,\n",
        "    validation_data = ([X_test_essay,X_test_school_state,X_test_project_grade_category,X_test_clean_categories,X_test_clean_subcategories,X_test_teacher_prefix ,X_test_previousproject_price],y_test),\n",
        "     epochs = 14,batch_size=5000, callbacks=tensorboard_callback)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.4501 - auroc: 0.4167 - val_loss: 0.4253 - val_auroc: 0.5076\n",
            "Epoch 2/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4266 - auroc: 0.5797 - val_loss: 0.4264 - val_auroc: 0.5815\n",
            "Epoch 3/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4255 - auroc: 0.5879 - val_loss: 0.4253 - val_auroc: 0.5786\n",
            "Epoch 4/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4252 - auroc: 0.5884 - val_loss: 0.4251 - val_auroc: 0.5809\n",
            "Epoch 5/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4251 - auroc: 0.5901 - val_loss: 0.4251 - val_auroc: 0.5837\n",
            "Epoch 6/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4250 - auroc: 0.5919 - val_loss: 0.4250 - val_auroc: 0.5847\n",
            "Epoch 7/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4249 - auroc: 0.5933 - val_loss: 0.4248 - val_auroc: 0.5897\n",
            "Epoch 8/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4246 - auroc: 0.6030 - val_loss: 0.4244 - val_auroc: 0.6122\n",
            "Epoch 9/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4241 - auroc: 0.6116 - val_loss: 0.4238 - val_auroc: 0.6140\n",
            "Epoch 10/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4234 - auroc: 0.6102 - val_loss: 0.4227 - val_auroc: 0.6149\n",
            "Epoch 11/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4220 - auroc: 0.6197 - val_loss: 0.4210 - val_auroc: 0.6326\n",
            "Epoch 12/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4155 - auroc: 0.6880 - val_loss: 0.4097 - val_auroc: 0.7237\n",
            "Epoch 13/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4006 - auroc: 0.7445 - val_loss: 0.3954 - val_auroc: 0.7333\n",
            "Epoch 14/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3791 - auroc: 0.7646 - val_loss: 0.3877 - val_auroc: 0.7353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde1756a0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fTA8Jg18Hw1",
        "colab_type": "text"
      },
      "source": [
        "#Conclusion\n",
        "Here Model1 gives 0.73 AUC value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzFkUc4tQeww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMAOS2Vsy8gc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 1. Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "### 2. Please go through this link https://keras.io/getting-started/functional-api-guide/ and check the 'Multi-input and multi-output models' then you will get to know how to give multiple inputs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCZQ_HUgy8gv",
        "colab_type": "text"
      },
      "source": [
        "### Model-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puefoiDOy8is",
        "colab_type": "text"
      },
      "source": [
        "Use the same model as above but for 'input_seq_total_text_data' give only some words in the sentance not all the words. Filter the words as below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkWKnI-1y8jo",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Train the TF-IDF on the Train data <br>\n",
        "2. Get the idf value for each word we have in the train data. <br>\n",
        "3. Remove the low idf value and high idf value words from our data. Do some analysis on the Idf values and based on those values choose the low and high threshold value. Because very frequent words and very very rare words don't give much information. (you can plot a box plots and take only the idf scores within IQR range and corresponding words)<br>\n",
        "4. Train the LSTM after removing the Low and High idf value words. (In model-1 Train on total data but in Model-2 train on data after removing some words based on IDF values)\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPlkhqm_29vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGf3kb7-WkZW",
        "colab_type": "code",
        "outputId": "acf1af0c-9148-4e45-c2cd-5e4f36158c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df = 1)\n",
        "\n",
        "tfidf.fit(X_train['essay'])\n",
        "response = tfidf.transform(X_train['essay'])\n",
        "\n",
        "idf = tfidf.idf_\n",
        "dic = dict(zip(tfidf.get_feature_names(), idf))\n",
        "\n",
        "from collections import OrderedDict \n",
        "dict1 = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1])}\n",
        "print(len(dict1))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jDn0r74A6me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "words = []\n",
        "for key, value in dict1.items():\n",
        "  count = count +1\n",
        "  if(count> 10000 and count < 40000):\n",
        "    words.append(key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5QN094AK8j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del dic , dict1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK5tLLJyK52C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(words)\n",
        "\n",
        "X_train_essay = t.texts_to_sequences(X_train['essay'])\n",
        "X_test_essay = t.texts_to_sequences(X_test['essay'])\n",
        "\n",
        "X_train_essay = pad_sequences(X_train_essay, maxlen=340, padding='post')\n",
        "X_test_essay = pad_sequences(X_test_essay,  maxlen=340, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgozJrnTLvHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('folder/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = values[1:]\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPVRSchp-wSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(t.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "del embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DFI-7PuKpSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total_text\n",
        "input_layer1 = Input(shape=(340,))\n",
        "#\n",
        "embedding1 = Embedding(48955, 300,weights=[embedding_matrix], input_length=340)(input_layer1)  #56381\n",
        "lstm = LSTM(64,return_sequences=True)(embedding1)\n",
        "flatten1 = Flatten()(lstm)\n",
        "\n",
        "#school_state\n",
        "input_layer2 = Input(shape=(1,))\n",
        "embedding2 = Embedding(51, 5, input_length=1)(input_layer2)\n",
        "flatten2 = Flatten()(embedding2)\n",
        "\n",
        "#project_grade_category\n",
        "input_layer3 = Input(shape=(1,))\n",
        "embedding3 = Embedding(4, 5, input_length=1)(input_layer3)\n",
        "flatten3 = Flatten()(embedding3)\n",
        "\n",
        "#clean_category\n",
        "input_layer4 = Input(shape=(1,))\n",
        "embedding4 = Embedding(51, 5, input_length=1)(input_layer4)\n",
        "flatten4 = Flatten()(embedding4)\n",
        "\n",
        "#clean_subcategories\n",
        "input_layer5 = Input(shape=(1,))\n",
        "embedding5 = Embedding(401, 20, input_length=1)(input_layer5)\n",
        "flatten5 = Flatten()(embedding5)\n",
        "\n",
        "#teacher_prefix\n",
        "input_layer6 = Input(shape=(1,))\n",
        "embedding6 = Embedding(5, 5, input_length=1)(input_layer6)\n",
        "flatten6 = Flatten()(embedding6)\n",
        "\n",
        "#price , teacher_number_of_previously_posted_projects\n",
        "input_layer7 = Input(shape=(2,))\n",
        "dense1 = Dense(2)(input_layer7)\n",
        "\n",
        "merged = Concatenate(axis = -1)([flatten1,flatten2,flatten3,flatten4,flatten5,flatten6,dense1])\n",
        "dense2 = Dense(128,activation = \"sigmoid\")(merged)\n",
        "\n",
        "dense3 = Dense(64,activation = \"sigmoid\")(dense2)\n",
        "\n",
        "dense4 = Dense(64,activation = \"sigmoid\")(dense3)\n",
        "\n",
        "dense5 = Dense(32,activation = \"sigmoid\")(dense4)\n",
        "\n",
        "dense6 = Dense(32,activation = \"sigmoid\")(dense5)\n",
        "\n",
        "dense7 = Dense(32,activation = \"sigmoid\")(dense6)\n",
        "\n",
        "output = Dense(2,activation = \"softmax\")(dense7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9jBRR0xLSSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_layer1,input_layer2,input_layer3,input_layer4,input_layer5,input_layer6,input_layer7],outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[auroc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMmf0LBeaeph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "740a7ca3-ef68-4ae5-96f8-c71b7b298559"
      },
      "source": [
        "model.fit(\n",
        "    [X_train_essay,X_train_school_state,X_train_project_grade_category,X_train_clean_categories,X_train_clean_subcategories,X_train_teacher_prefix ,X_train_previousproject_price],y_train ,\n",
        "    validation_data = ([X_test_essay,X_test_school_state,X_test_project_grade_category,X_test_clean_categories,X_test_clean_subcategories,X_test_teacher_prefix ,X_test_previousproject_price],y_test),\n",
        "     epochs = 14,batch_size=5000, callbacks=tensorboard_callback)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.4510 - auroc: 0.4167 - val_loss: 0.4255 - val_auroc: 0.5103\n",
            "Epoch 2/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4272 - auroc: 0.5797 - val_loss: 0.4269 - val_auroc: 0.5792\n",
            "Epoch 3/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4260 - auroc: 0.5879 - val_loss: 0.4254 - val_auroc: 0.5880\n",
            "Epoch 4/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4252 - auroc: 0.5884 - val_loss: 0.4253 - val_auroc: 0.5881\n",
            "Epoch 5/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4251 - auroc: 0.5901 - val_loss: 0.4251 - val_auroc: 0.5901\n",
            "Epoch 6/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4250 - auroc: 0.5919 - val_loss: 0.4249 - val_auroc: 0.5914\n",
            "Epoch 7/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4246 - auroc: 0.5933 - val_loss: 0.4242 - val_auroc: 0.5920\n",
            "Epoch 8/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4250 - auroc: 0.6030 - val_loss: 0.4234 - val_auroc: 0.6023\n",
            "Epoch 9/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4241 - auroc: 0.6116 - val_loss: 0.4232 - val_auroc: 0.6103\n",
            "Epoch 10/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4237 - auroc: 0.6102 - val_loss: 0.4221 - val_auroc: 0.6110\n",
            "Epoch 11/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4220 - auroc: 0.6408 - val_loss: 0.4203 - val_auroc: 0.6201\n",
            "Epoch 12/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4149 - auroc: 0.7201 - val_loss: 0.4092 - val_auroc: 0.6882\n",
            "Epoch 13/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3782 - auroc: 0.7633 - val_loss: 0.3850 - val_auroc: 0.7446\n",
            "Epoch 14/14\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3506 - auroc: 0.7831 - val_loss: 0.3602 - val_auroc: 0.7655\n",
            "<tensorflow.python.keras.callbacks.History at 0x7fde1456a0b5>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIANNbTr7tiw",
        "colab_type": "text"
      },
      "source": [
        "#Conclusion\n",
        "Here Model2 gives 0.76 AYC value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khaKjIYzy8mo",
        "colab_type": "text"
      },
      "source": [
        "### Model-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhJaw5pqy8nQ",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
        "ref: https://i.imgur.com/fkQ8nGo.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyUyVy9_y8ni",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- __input_seq_total_text_data__: <br>\n",
        "<pre>\n",
        "    . Use text column('essay'), and use the Embedding layer to get word vectors. <br>\n",
        "    . Use given predefined glove word vectors, don't train any word vectors. <br>\n",
        "    . Use LSTM that is given above, get the LSTM output and Flatten that output. <br>\n",
        "    . You are free to preprocess the input text as you needed. <br>\n",
        "</pre>\n",
        "- __Other_than_text_data__:<br>\n",
        "<pre>\n",
        "    . Convert all your Categorical values to onehot coded and then concatenate all these onehot vectors <br>\n",
        "    . Neumerical values and use <a href='https://keras.io/getting-started/sequential-model-guide/#sequence-classification-with-1d-convolutions'>CNN1D</a> as shown in above figure. <br>\n",
        "    . You are free to choose all CNN parameters like kernel sizes, stride.<br>\n",
        "    \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwdwMwfwgsUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# school_state\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['school_state'].values) \n",
        "X_train_school_state = vectorizer.transform(X_train['school_state'].values)\n",
        "X_test_school_state = vectorizer.transform(X_test['school_state'].values)\n",
        "\n",
        "# project_grade_category\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['project_grade_category'].values) \n",
        "X_train_project_grade_category = vectorizer.transform(X_train['project_grade_category'].values)\n",
        "X_test_project_grade_category = vectorizer.transform(X_test['project_grade_category'].values)\n",
        "\n",
        "# clean_categories\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['clean_categories'].values) \n",
        "X_train_project_clean_categories = vectorizer.transform(X_train['clean_categories'].values)\n",
        "X_test_project_clean_categories = vectorizer.transform(X_test['clean_categories'].values)\n",
        "\n",
        "#clean_subcategories\n",
        "vectorizer = CountVectorizer()\n",
        "clean_subcategories = vectorizer.fit_transform(X['clean_subcategories'].values)\n",
        "X_train_clean_subcategories , X_test_clean_subcategories = train_test_split(clean_subcategories , test_size = 0.25) \n",
        "\n",
        "# teacher_prefix\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['teacher_prefix'].values) \n",
        "X_train_teacher_prefix = vectorizer.transform(X_train['teacher_prefix'].values)\n",
        "X_test_teacher_prefix = vectorizer.transform(X_test['teacher_prefix'].values)\n",
        "\n",
        "# price\n",
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_train['price'].values.reshape(1,-1))\n",
        "X_train_price_norm = normalizer.transform(X_train['price'].values.reshape(1,-1))\n",
        "X_test_price_norm = normalizer.transform(X_test['price'].values.reshape(1,-1))\n",
        "\n",
        "# teacher_number_of_previously_posted_projects\n",
        "X_train_previousproject_price = X_train[['teacher_number_of_previously_posted_projects']]\n",
        "X_test_previousproject_price = X_test[['teacher_number_of_previously_posted_projects']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Hcn8hntekM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import coo_matrix, hstack\n",
        "X_tr = hstack((X_train_school_state, X_train_project_grade_category, X_train_project_clean_categories, X_train_clean_subcategories,X_train_teacher_prefix, X_train_price_norm[0].reshape(-1,1), X_train_previousproject_price)).tocsr()\n",
        "\n",
        "X_te = hstack((X_test_school_state, X_test_project_grade_category, X_test_project_clean_categories, X_test_clean_subcategories, X_test_teacher_prefix, X_test_price_norm[0].reshape(-1,1) ,X_test_previousproject_price)).tocsr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7R8ju6ngs3g",
        "colab_type": "text"
      },
      "source": [
        "Structure Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uzxcQ1jfKyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer1 = Input(shape=(340,))\n",
        "\n",
        "embedding1 = Embedding(50477, 300,weights=[embedding_matrix] input_length=340)(input_layer1)  #56381\n",
        "lstm = LSTM(64,return_sequences=True)(embedding1)\n",
        "flatten1 = Flatten()(lstm)\n",
        "\n",
        "input_layer2 = Input(shape=(101,1))\n",
        "conv1 = Conv1D(30, 3, strides=1, padding='same', data_format='channels_last', dilation_rate=1, activation='relu')(input_layer2)\n",
        "conv2 = Conv1D(30, 3, strides=1, padding='same', data_format='channels_last', dilation_rate=1, activation='relu')(conv1)\n",
        "flatten2 = Flatten()(conv2)\n",
        "\n",
        "merged = Concatenate(axis = -1)([flatten1,flatten2])\n",
        "\n",
        "dense1 = Dense(128)(merged)\n",
        "dense2 = Dense(64, activation=\"sigmoid\")(dense1)\n",
        "dense3 = Dense(64, activation=\"sigmoid\")(dense2)\n",
        "dense4 = Dense(32, activation=\"sigmoid\")(dense3)\n",
        "dense5 = Dense(32, activation=\"sigmoid\")(dense4)\n",
        "dense6 = Dense(32, activation=\"sigmoid\")(dense5)\n",
        "dense7 = Dense(32, activation=\"sigmoid\")(dense6)\n",
        "output = Dense(2 , activation=\"softmax\")(dense7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YEc9hJS35Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_layer1,input_layer2],outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[auroc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGX4zp6g7fEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr1 = X_tr.todense()\n",
        "X_te1 = X_te.todense()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk9_t6Aw8sRD",
        "colab_type": "code",
        "outputId": "63a5ad48-d0e8-474b-b176-f6027effac0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import datetime\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOuwSLiGoArS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "52de080d-6d71-443c-e487-41616eebe062"
      },
      "source": [
        "model.fit(\n",
        "    [X_train_essay,X_tr1],y_train ,\n",
        "    validation_data = ([X_test_essay,X_te1],y_test),\n",
        "     epochs = 15,batch_size=5000,callbacks = tensorboard_callback)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/4\n",
            "4/4 [==============================] - 22s 1s/step - loss: 0.4220 - auroc: 0.7198 - val_loss: 0.4203 - val_auroc: 0.6983\n",
            "Epoch 2/4\n",
            "4/4 [==============================] - 22s 1s/step - loss: 0.4149 - auroc: 0.7249 - val_loss: 0.4182 - val_auroc: 0.7003\n",
            "Epoch 3/4\n",
            "4/4 [==============================] - 22s 1s/step - loss: 0.3902 - auroc: 0.7301 - val_loss: 0.4096 - val_auroc: 0.7088\n",
            "Epoch 4/4\n",
            "4/4 [==============================] - 22s 1s/step - loss: 0.3782 - auroc: 0.7382 - val_loss: 0.3932 - val_auroc: 0.7112\n",
            "<tensorflow.python.keras.callbacks.History at 0x7fd8eb14c0f0>    \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2Nw-zd6TO-",
        "colab_type": "text"
      },
      "source": [
        "#conclusion\n",
        "Here Model3 gives around 0.71 AUC value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nznZ6JQK9K8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQSuaPPHyaJV",
        "colab_type": "text"
      },
      "source": [
        "#Final Conclusion\n",
        "finnaly we can conclude that model2 gives better result because in model 2 we have removed  unnacessary words."
      ]
    }
  ]
}