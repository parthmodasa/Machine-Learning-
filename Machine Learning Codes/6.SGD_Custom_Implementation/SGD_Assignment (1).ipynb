{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD_Custom_Implementation (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2S-uFqwSvmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from math import log\n",
        "import math\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUxLkBjISvmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xexp5GYNSvmz",
        "colab_type": "code",
        "outputId": "97160621-547a-4b87-dd52-2b273aeb8ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54vJVc_KSvm9",
        "colab_type": "text"
      },
      "source": [
        " Split data  into train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pKAn1-ASvm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r97pFTgrSvnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jykLIXZNSvnJ",
        "colab_type": "code",
        "outputId": "114b92fe-5894-4c0b-ccbe-b153fb37b0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0-M6oXASvnO",
        "colab_type": "text"
      },
      "source": [
        " Apply sklearn's SGDClassifier and find weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sShoMeocSvnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm6wi8L2SvnU",
        "colab_type": "code",
        "outputId": "e2d08a0c-5fd3-46f0-f479-d01a6f0aac98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4WFoxgASvnc",
        "colab_type": "code",
        "outputId": "1bc0fd48-7b22-4513-802f-9c8951121aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "clf.fit(X=X_train, y=y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 10 epochs took 0.10 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOBvEchCSvnr",
        "colab_type": "text"
      },
      "source": [
        "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbn61rrXSvnt",
        "colab_type": "text"
      },
      "source": [
        "### Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bA5yR3Svnv",
        "colab_type": "text"
      },
      "source": [
        "- Load the datasets(train and test) into the respective arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7183hFBSvnv",
        "colab_type": "text"
      },
      "source": [
        "- Initialize the weight_vector and intercept term randomly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdLeFU0USvnx",
        "colab_type": "text"
      },
      "source": [
        "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEVtAlO1Svny",
        "colab_type": "text"
      },
      "source": [
        "- for each epoch:\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
        "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
        "        $b^{(t+1)} ← (b^t +  α(y_n - σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
        "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmRH4UpSvny",
        "colab_type": "text"
      },
      "source": [
        "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbZf9p5gSvn1",
        "colab_type": "text"
      },
      "source": [
        "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dibqijy65sV8",
        "colab_type": "text"
      },
      "source": [
        "Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8neHBuj5zkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(w,x,b):\n",
        "  Z = np.dot(w,x)+b\n",
        "  return(1/(1 + np.exp(-Z)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejm-hPJd6Fpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mod(w):\n",
        "  sum1 = 0\n",
        "  for i in w:\n",
        "    sum1  = sum1 + i*i\n",
        "  return(math.sqrt(sum1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vu4_9755x0p",
        "colab_type": "text"
      },
      "source": [
        "Initialize values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kX_Te59jMB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = np.zeros_like(X_train[0])\n",
        "b = 0\n",
        "eta0  = 0.0001\n",
        "alpha = 0.0001\n",
        "N = len(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70cahnl2mMHk",
        "colab_type": "text"
      },
      "source": [
        "Find initial loss and append it to list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXqEW-q1mLxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_LOSS = []\n",
        "TEST_LOSS = []\n",
        "\n",
        "\n",
        "#Train loss\n",
        "loss = 0\n",
        "for i in range(len(X_train)):\n",
        "  loss += (np.log(sigmoid(w,X_train[i],b)) * y_train[i] + np.log(1 - sigmoid(w,X_train[i],b)) * (1 - y_train[i]))\n",
        "loss = (-1)*loss/len(X_train) \n",
        "TRAIN_LOSS.append(loss)\n",
        "\n",
        "#Test Loss\n",
        "loss = 0\n",
        "for i in range(len(X_test)):\n",
        "  loss += (np.log(sigmoid(w,X_test[i],b)) * y_test[i] + np.log(1 - sigmoid(w,X_test[i],b)) * (1 - y_test[i]))\n",
        "loss = (-1)*loss/len(X_test) \n",
        "TEST_LOSS.append(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzBpoUbKO2mo",
        "colab_type": "text"
      },
      "source": [
        "Apply algorithm to find weights and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6v1sMMm52m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "l = len(X_train)\n",
        "for ep in range(20):\n",
        "\n",
        "  '''Update weights and intercept for each point'''\n",
        "  for i in range(len(X_train)):\n",
        "    w = (1 - (0.0001)/l)*w + 0.0001 * X_train[i] * (y_train[i] - sigmoid(w,X_train[i],b))\n",
        "    \n",
        "    b = b + 0.0001*(y_train[i]-sigmoid(w,X_train[i],b))\n",
        "\n",
        "  ''' Find Loss'''\n",
        "  #Train loss\n",
        "  loss = 0\n",
        "  for i in range(len(X_train)):\n",
        "    loss += (np.log(sigmoid(w,X_train[i],b)) * y_train[i] + np.log(1 - sigmoid(w,X_train[i],b)) * (1 - y_train[i]))\n",
        "  loss = (-1)*loss/len(X_train) \n",
        "  TRAIN_LOSS.append(loss)\n",
        "\n",
        "  #Test Loss\n",
        "  loss = 0\n",
        "  for i in range(len(X_test)):\n",
        "    loss += (np.log(sigmoid(w,X_test[i],b)) * y_test[i] + np.log(1 - sigmoid(w,X_test[i],b)) * (1 - y_test[i]))\n",
        "  loss = (-1)*loss/len(X_test) \n",
        "  TEST_LOSS.append(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn6bV78QOGC7",
        "colab_type": "text"
      },
      "source": [
        "Print weights and intercept of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tnOSoT1OFvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0a9eded7-0972-4c81-c592-aa4010af2098"
      },
      "source": [
        "print(\"Weights are :\",w)\n",
        "\n",
        "print(\"Intercept :\" ,b)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights are : [-4.29288445e-01  1.92871197e-01 -1.48268287e-01  3.38050859e-01\n",
            " -2.20618116e-01  5.69556730e-01 -4.45141511e-01 -9.00148624e-02\n",
            "  2.21541575e-01  1.73523343e-01  1.98483126e-01 -3.89253433e-04\n",
            " -8.10827249e-02  3.39028140e-01  2.29311637e-02]\n",
            "Intercept : -0.8893357037092375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHcqMp6gAGIN",
        "colab_type": "text"
      },
      "source": [
        "Train LOSS vs Test LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQUZVIT3AWEq",
        "colab_type": "code",
        "outputId": "5fe735d2-4932-4e48-ec4a-48639543c6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter([i for i in range(21)] ,TRAIN_LOSS, alpha=0.5)\n",
        "plt.scatter([i for i in range(21)] ,TEST_LOSS, alpha=0.5)\n",
        "plt.title('LOSS changes as per epoches')\n",
        "plt.xlabel('epoches')\n",
        "plt.ylabel('LOSS')\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFXKCMDOzQk4QZmZW6P8D7kqw9/AhACIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd25i9n5i53o",
        "colab_type": "code",
        "outputId": "6af61649-6e36-445f-a4af-1243b1a37f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(TRAIN_LOSS)\n",
        "print(TEST_LOSS)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6931471805594285, 0.40403483540154406, 0.38840566283891775, 0.3831502802782614, 0.38078871559282973, 0.379607672225668, 0.37898564992939876, 0.3786485612275279, 0.378462691564947, 0.3783590220296394, 0.37830072273472676, 0.37826772813870235, 0.37824895464056285, 0.3782382205698343, 0.37823205354111267, 0.3782284922246273, 0.37822642377879395, 0.37822521431092593, 0.37822450142930525, 0.37822407720132234, 0.37822382185251546]\n",
            "[0.6931471805600672, 0.4051805305933462, 0.390082036516956, 0.38502563017730945, 0.3827437054953831, 0.38159384442002586, 0.3809828490732264, 0.38064856398667934, 0.3804623679553379, 0.38035738397577284, 0.3802976393667366, 0.3802633727664767, 0.38024357524785823, 0.38023205220637907, 0.38022529124297644, 0.3802212882173815, 0.38021889316530333, 0.3802174426735918, 0.3802165518697225, 0.38021599608955914, 0.3802156432528444]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVU5AoRvo3jM",
        "colab_type": "text"
      },
      "source": [
        "#Compare weights and intercept"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjNtPTuMFqLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6ab51fb4-5b24-45fd-a44e-755cfb980161"
      },
      "source": [
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.00592153,  0.00739555,  0.00032207, -0.00339321, -0.01243141,\n",
              "          0.00939094,  0.00728331,  0.00407327,  0.01226838, -0.00731792,\n",
              "          0.00143122, -0.00460841, -0.00147903,  0.00050012,  0.00026395]]),\n",
              " array([-0.03619741]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48gx6wQKSvoE",
        "colab_type": "code",
        "outputId": "e0170219-3dbf-4203-87be-ce777816bc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9524266666666666\n",
            "0.95024\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}